# PolyStats
## Состав команды: 
1.	Козлов Максим Алексеевич 5130904/30105
2.	Лельков Константин Алексеевич 5130904/30105
3.	Леонтьев Алексей Константинович 5130904/30105
4.	Пономарев Вячеслав Игоревич 5130904/30105

# Определение проблемы: 
Студенты Политеха сталкиваются с трудностями в отслеживании своего прогресса по множеству предметов, лабораторных и контрольных работ. Нет единой системы, где можно видеть: 
1. По каким предметам что нужно сдать 
2. Что уже выполнено 
3. Что осталось сделать 
4. Общий прогресс по семестру

# Выработка требований:
Для выработки требований к проекту были разработаны пользовательские сценарии
**Сценарий 1: Первоначальная настройка трекера**  
Как студент Политеха, я хочу быстро настроить трекер под свою учебную нагрузку, чтобы сразу начать отслеживать прогресс без ручного ввода данных.

**Сценарий 2: Ежедневное обновление прогресса**  
Как активный студент, я хочу быстро отмечать выполненные работы, чтобы видеть актуальный прогресс и понимать, что делать дальше.

**Сценарий 3: Анализ успеваемости перед сессией**  
Как студент перед экзаменационной сессией, я хочу видеть общую картину по всем предметам, чтобы понять, на чем сосредоточиться в оставшееся время.

# Разработка архитектуры и детальное проектирование

**Ожидаемое число пользователей:** 10,000 активных пользователей в сутки
**Период хранения данных:** 7 лет (полный цикл обучения + 2 года архив)
**Пиковая нагрузка:** период сессии (декабрь-январь, май-июнь)

## Характер нагрузки на сервис
Соотношение R/W нагрузки
Чтение (R): 70% (просмотр прогресса, статистики, списков)
Это объясняется тем, что пользователи чаще смотрят свой прогресс, чем вносят изменения

Запись (W): 30% (добавление предметов, обновление прогресса)
Изменения происходят только при сдаче работ или настройке предметов

## Объемы трафика
Средний размер запроса: 2 KB
Включает заголовки HTTP и небольшие JSON-тела запросов (например, {"name": "ЛР1"})

Средний размер ответа: 10 KB
Содержит данные предмета с несколькими активностями и метаданными

Ожидаемый трафик: 50 GB/месяц
Рассчитано исходя из 10,000 пользователей, делающих по 10 запросов в день с учетом пиковой нагрузки

RPS (запросов в секунду): ~100 в пиковые часы
При равномерном распределении активности 30% пользователей работают в вечерние часы

Объемы дисковой системы
Размер пользователя: ~5 KB
Включает email, хэш пароля, настройки профиля и метаданные

Размер предмета: ~2 KB
Содержит название, настройки отображения и связи с пользователем

Размер активности: ~1 KB
Включает название работы, прогресс и тип задания

Общий объем за 7 лет:

10,000 пользователей × 10 предметов × 20 активностей = 2,000,000 записей

Общий объем: ~8 GB + 30% резерв = 10.5 GB
Расчет основан на предположении, что средний студент имеет 10 предметов в семестре по 20 работ в каждом

# Диаграммы C4 Model
## Контекст
<img width="601" height="966" alt="image" src="https://github.com/user-attachments/assets/065b36ed-f0d8-4692-8316-dd6bfdde55e0" />

## Контейнеры
<img width="495" height="963" alt="image" src="https://github.com/user-attachments/assets/06893783-9aaf-4d48-89f7-7fa26e95ea03" />

# Контракты API
Информация о контрактах доступна по ссылке http://polystats.ddns.net/docs

# Нефункциональные требования
Производительность:
Время отклика API: < 200 мс для 95% GET-запросов

Загрузка интерфейса: < 2 секунды до интерактивности

Пропускная способность: 150 RPS в пиковые часы (сессия)

Доступность:
Uptime: 99.5% (≈3.5 часа простоя в месяц)

Время восстановления (MTTR): < 1 часа

Масштабируемость:
Горизонтальное масштабирование: +3 инстанса за 15 минут

Пиковая нагрузка: Обработка 3,000 одновременных пользователей

Рост нагрузки в 10 раз: Автомасштабирование при RPS > 100

Надежность данных:
Резервное копирование: Ежедневно + инкрементальные копии

Сохранность данных: Гарантия целостности при 99.9% запросов

Хранение: 7 лет + 2 года архив

Мониторинг:
Алертинг: При времени отклика > 500 мс или ошибках > 1%

Метрики в реальном времени: RPS, latency, ошибки, использование CPU/RAM

Пиковые периоды (сессия):
Подготовка: Увеличение ресурсов за 2 недели до сессии

Пиковая нагрузка: 300% от обычной нагрузки

Пост-сессия: Автоматическое снижение ресурсов

Обоснование: Требования основаны на 10,000 активных пользователей с предсказуемыми пиками во время экзаменационных сессий.

# Базы данных
<img width="618" height="752" alt="image" src="https://github.com/user-attachments/assets/dceead26-dc2a-480a-847f-a28f60c83f3f" />

## Обеспечение нефункциональных требований БД
База данных спроектирована с учётом выполнения нефункциональных требований по производительности, масштабируемости и надёжности для 10,000+ пользователей.

Нормализованная структура обеспечивает эффективное хранение и быстрый доступ к данным за счёт разделения информации по специализированным таблицам (users, subjects, activities). Это исключает дублирование данных и минимизирует объём операций ввода-вывода.

Производительность достигается за счёт индексации всех внешних ключей (user_id, subject_id) и использования покрывающих индексов для частых запросов. PostgreSQL Query Optimizer обеспечивает выполнение запросов < 200 мс для 95% операций чтения.

Масштабируемость обеспечивается архитектурой с поддержкой:

Read Replicas (3+ реплики для распределения нагрузки чтения)

Connection Pooling через PgBouncer (до 400 соединений)

Возможностью партиционирования таблиц по user_id при росте >100,000 пользователей

Надежность (99.5% uptime) гарантируется:

Синхронной репликацией с автоматическим failover

Point-in-Time Recovery (восстановление до любой точки за 7 дней)

Ежедневными полными бэкапами + инкрементальными каждый час

WAL архивацией для непрерывной защиты данных

Целостность данных обеспечивается внешними ключами с каскадным удалением, что исключает появление некорректных связей и автоматически очищает зависимые записи.

Емкость хранения рассчитана на 7 лет работы:

Общий объём: ~10.5 GB (8 GB данных + резерв)

Стратегия хранения: горячие данные (1 год), тёплые (3 года), холодные (архив)

Такая архитектура позволяет системе стабильно работать с прогнозируемой нагрузкой в 10,000 пользователей в день и масштабироваться при дальнейшем росте.

## Схема масштабирования сервиса
При увеличении количества пользователей в 10 раз могут быть внедрены следующие технологии:

Балансировщик нагрузки (Nginx/HAProxy). Распределение трафика между несколькими серверами приложения позволит оптимально использовать доступные вычислительные ресурсы, не допускать перегрузки, обеспечить отказоустойчивость и горизонтальное масштабирование.

Кэш Redis. Кэширование часто запрашиваемых данных (списки предметов, статистика) позволит уменьшить нагрузку на БД и ускорить получение ответа API до 50-100 мс.

Реплики для чтения БД. Так как 70% запросов в базу данных составляет чтение, при увеличении нагрузки потребуются дополнительные read replicas PostgreSQL для распределения нагрузки чтения и снижения нагрузки на основную базу данных.

Контейнеризация и оркестрация (Docker + Kubernetes). Автоматическое масштабирование количества инстансов приложения в зависимости от нагрузки (CPU/RPS метрики).

CDN для статических ресурсов. Распределение статических файлов (JS, CSS, изображения) по географически распределённым серверам для уменьшения времени загрузки интерфейса.

Мониторинг и алертинг (Prometheus + Grafana). Автоматическое обнаружение узких мест и оповещение при превышении пороговых значений (latency > 500 мс, ошибки > 1%).

# Кодирование и отладка
## Стек используемых технологий:
### Backend
Python - основной язык программирования серверной части
FastAPI - современный асинхронный веб-фреймворк для создания API
Asyncpg - асинхронный драйвер для работы с PostgreSQL
SQLAlchemy - ORM для работы с базой данных
Alembic - система миграций базы данных
Pydantic - валидация данных и сериализация
PostgreSQL - реляционная база данных
JWT (JSON Web Tokens) - аутентификация пользователей
Uvicorn - ASGI-сервер для запуска FastAPI приложения
Swagger/OpenAPI - автоматическая документация API
### Frontend
TypeScript - язык программирования с статической типизацией
React - JavaScript-библиотека для разработки пользовательских интерфейсов
Vite - инструмент для эффективной сборки проектов на React
React Router - маршрутизация в одностраничном приложении
Axios - HTTP-клиент для взаимодействия с API
Tailwind CSS - CSS-фреймворк для стилизации
React Query/TanStack Query - управление состоянием и кэширование API-запросо
### Инфраструктура и инструменты
Docker - контейнеризация приложения
Docker Compose - оркестрация многоконтейнерных приложений
PostgreSQL - основное хранилище данных
Git - система контроля версий
GitHub Actions - CI/CD для автоматического тестирования и деплоя
pytest - фреймворк для unit-тестирования
React Testing Library - тестирование React-компонентов

## Тестирование
Запуск тестов:
docker-compose -f docker-compose.test.yml up --build -d

Unit-тесты
Проверяют корректную работу моделей БД, Pydantic схем, бизнес-логики и утилитарных функций.

Интеграционные тесты
Проверяют полные пользовательские сценарии: регистрация → добавление предметов → отслеживание прогресса → получение статистики.

##Сборка
Для сборки и запуска всего проекта выполните:
docker-compose up --build -d

Остановка:
docker-compose down
